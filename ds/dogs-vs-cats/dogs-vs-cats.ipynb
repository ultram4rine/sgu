{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этой практике вы познакомитесь с тем как строить пайплайн для решения задачи обучения с учителем. На самом деле строить пайплайн с нуля даже для такой задачи как классификация кошек и собак довольно трудоемко для первой практики, поэтому многие шаги я уже приготовил. Вам нужно реализовать ключевые куски чтобы сложить картину целиком.\n",
    "Для того чтобы выполнить практику, поставьте [Anaconda](https://www.anaconda.com/download) - она содержит нужные для работы библиотеки."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Зарегистрируйтесь на платформе https://kaggle.com и посмотрите конкурс https://www.kaggle.com/c/dogs-vs-cats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Скачайте данные этого конкурса https://www.kaggle.com/c/3362/download-all. Наш проект будет построен по т.н. схеме [cookiecutter](https://drivendata.github.io/cookiecutter-data-science/#cookiecutter-data-science) (прочитать про неё полезно, но не обязательно), поэтому скачанные данные распакуйте и поместите в папку `data/` внутри проекта (на деле если вы используете ссылку выше нужно распаковать дважды - архив и архивы внутри архива). Если вы используете `git`, то добавьте папку `data/` в файл `.gitignore`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данные для каждой практики персональны для каждого студента. Введите свое имя, фамилию и группу в строковую переменную STUDENT_ID (в произвольной форме) - это ваш уникальный идентификатор."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "STUDENT_ID = \"Radyushin_Vadim_411\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтение данных\n",
    "===="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обработаем данные. Этот шаг я сделаю за вас в силу некоторой его трудоемкости. Используем библиотеки pandas, numpy и Pillow.\n",
    "- Введение в pandas и numpy можно посмотреть в первом уроке курса mlcourse_open: \n",
    "- https://github.com/Yorko/mlcourse.ai/blob/master/jupyter_russian/topic01_pandas_data_analysis/lesson1_part0_numpy.ipynb\n",
    "- https://github.com/Yorko/mlcourse.ai/blob/master/jupyter_russian/topic01_pandas_data_analysis/lesson1_part1_pandas_intro.ipynb\n",
    "- Pillow - одна из самых распространенных библиотек для работы с изображениями в python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "           filename  is_cat\n",
       "0      dog.1182.jpg   False\n",
       "1      cat.4963.jpg    True\n",
       "2      dog.9375.jpg   False\n",
       "3        dog.12.jpg   False\n",
       "4     dog.11321.jpg   False\n",
       "...             ...     ...\n",
       "4995   cat.1182.jpg    True\n",
       "4996   dog.4231.jpg   False\n",
       "4997   dog.4653.jpg   False\n",
       "4998  dog.11488.jpg   False\n",
       "4999    dog.998.jpg   False\n",
       "\n",
       "[5000 rows x 2 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>filename</th>\n      <th>is_cat</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>dog.1182.jpg</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>cat.4963.jpg</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>dog.9375.jpg</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>dog.12.jpg</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>dog.11321.jpg</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>4995</th>\n      <td>cat.1182.jpg</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>4996</th>\n      <td>dog.4231.jpg</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>4997</th>\n      <td>dog.4653.jpg</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>4998</th>\n      <td>dog.11488.jpg</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>4999</th>\n      <td>dog.998.jpg</td>\n      <td>False</td>\n    </tr>\n  </tbody>\n</table>\n<p>5000 rows × 2 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pathlib\n",
    "import hashlib\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "\n",
    "train_directory = pathlib.Path(\"data/train\")\n",
    "sample_size = 5000\n",
    "\n",
    "def initialize_random_seed():\n",
    "    \"\"\"Инициализирует ГПСЧ из STUDENT_ID\"\"\"\n",
    "    sha256 = hashlib.sha256()\n",
    "    sha256.update(STUDENT_ID.encode(\"utf-8\"))\n",
    "    \n",
    "    fingerprint = int(sha256.hexdigest(), 16) % (2**32) \n",
    "    \n",
    "    random.seed(fingerprint)\n",
    "    np.random.seed(fingerprint)\n",
    "\n",
    "\n",
    "def read_target_variable():\n",
    "    \"\"\"Прочитаем разметку фотографий из названий файлов\"\"\"\n",
    "    target_variable = {\n",
    "        \"filename\": [],\n",
    "        \"is_cat\": []\n",
    "    }\n",
    "    image_paths = list(train_directory.glob(\"*.jpg\"))\n",
    "    random.shuffle(image_paths)\n",
    "    for image_path in image_paths[:sample_size]:\n",
    "        filename = image_path.name\n",
    "        class_name = filename.split(\".\")[0]\n",
    "        target_variable[\"filename\"].append(filename)\n",
    "        target_variable[\"is_cat\"].append(class_name == \"cat\")\n",
    "\n",
    "    return pd.DataFrame(data=target_variable)\n",
    "\n",
    "\n",
    "initialize_random_seed()\n",
    "\n",
    "target_df = read_target_variable()\n",
    "target_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обработка изображений\n",
    "===="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используем изображения в качестве признакового описания. Признаками будут значения конкретных пикселей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "  0%|          | 0/5000 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "47d70b9c86c1411a9239dd0764a7348c"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[ 74,  73,  70, ...,  56,  61,  83],\n",
       "       [106, 109, 112, ..., 106,  97,  99],\n",
       "       [196, 195, 194, ..., 137, 111,  97],\n",
       "       ...,\n",
       "       [195, 193, 168, ...,  31,  34,  37],\n",
       "       [ 84,  70,  72, ..., 100,  99, 110],\n",
       "       [ 78,  80,  81, ...,  99,  98,  98]], dtype=uint8)"
      ]
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "from PIL import Image\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "\n",
    "def read_data(target_df):\n",
    "    \"\"\"Читает данные изображений и строит их признаковое описание\"\"\"\n",
    "    image_size = (100, 100)\n",
    "    features = []\n",
    "    target = []\n",
    "    for i, image_name, is_cat in tqdm_notebook(target_df.itertuples(), total=len(target_df)):\n",
    "        image_path = str(train_directory / image_name)\n",
    "        image = Image.open(image_path)\n",
    "        image = image.resize(image_size) # уменьшаем изображения\n",
    "        image = image.convert('LA') # преобразуем в Ч\\Б\n",
    "        pixels = np.asarray(image)[:, :, 0]\n",
    "        pixels = pixels.flatten()\n",
    "        features.append(pixels)\n",
    "        target.append(is_cat)\n",
    "    return np.array(features), np.array(target)\n",
    "\n",
    "features, target = read_data(target_df)\n",
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разбиение на обучающую и тестовую выборки\n",
    "====\n",
    "\n",
    "Сделайте обучающую и тестовую выборки в пропорции 80/20. Используйте библиотеку scikit-learn (метод train_test_split). \n",
    "\n",
    "Документация: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\n",
    "\n",
    "Советую изучить готовый пайплайн для другой задачи, чтобы примерно понимать что требуется делать дальше (в отличии от нашего пайплайна тут нет валидационного множества): https://scikit-learn.org/stable/auto_examples/linear_model/plot_sparse_logistic_regression_mnist.html \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[145, 159, 169, ...,  41,  40,  41],\n",
       "       [ 92, 109, 112, ..., 249, 250, 250],\n",
       "       [ 14,  16,  20, ..., 202, 209, 211],\n",
       "       ...,\n",
       "       [108, 116, 138, ...,  53,  49,  40],\n",
       "       [141, 140, 140, ..., 121, 121, 120],\n",
       "       [255, 255, 255, ..., 255, 255, 255]], dtype=uint8)"
      ]
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "features_train, features_test, target_train, target_test = train_test_split(features, target, train_size=0.8, test_size=0.2, random_state=42)\n",
    "features_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучение модели\n",
    "====\n",
    "\n",
    "Попробуйте обучить модель `sklearn.linear_model.SGDClassifier` на полученных данных. Если это занимает слишком много времени и ресурсов - уменьшайте размер выборки (переменная sample_size).\n",
    "\n",
    "Документация: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "SGDClassifier(eta0=0.5, learning_rate='constant')"
      ]
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "sgd_clf = SGDClassifier(max_iter=1000, tol=1e-3, eta0=0.5, learning_rate=\"constant\")\n",
    "sgd_clf.fit(features_train, target_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Настройка гиперпараметров\n",
    "====\n",
    "\n",
    "Подберите скорость обучения модели, оценивая долю верных ответов (scikit-learn accuracy_score) на валидационном множестве (подбираем параметр `eta0` в отрезке [0, 1] указав параметр `learning_rate=\"constant\"`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оценка результатов\n",
    "====\n",
    "\n",
    "Оцените долю верных ответов модели (scikit-learn accuracy_score). Каков уровень переобучения?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.52"
      ]
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(target_test, clf.predict(features_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нормализация данных\n",
    "====\n",
    "\n",
    "Сделайте нормализацию данных с помощью StandardScaler из библиотеки sklearn (scaler.fit_transform на train и validation, scaler.transform на test). Оцените долю верных ответов модели на тестовой выборке. Какова ситуация теперь?\n",
    "\n",
    "Документация: https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.523"
      ]
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "features_train_normalized = scaler.fit_transform(features_train)\n",
    "features_test_normalized = scaler.transform(features_test)\n",
    "\n",
    "sgd_clf.fit(features_train_normalized, target_train)\n",
    "\n",
    "accuracy_score(target_test, clf.predict(features_test_normalized))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сабмит на kaggle\n",
    "===="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Опционально) сделайте сабмит в конкурсе https://www.kaggle.com/c/dogs-vs-cats (это простой бейзлайн, не ожидайте высокого результата)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Примените RandomForest вместо SGDClassifier на этой задаче. Подберите количество деревьев, перебирая их в интервале от 100 до 400.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.61"
      ]
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_clf = RandomForestClassifier(n_estimators=300, max_depth=5, random_state=42)\n",
    "\n",
    "rf_clf.fit(features_train_normalized, target_train)\n",
    "\n",
    "accuracy_score(target_test, rf_clf.predict(features_test_normalized))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оцените качество RandomForest на кросс-валидации по пяти фолдам. Посмотрите на среднее и стандартное отклонение точности на кросс-валидации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([0.614, 0.597, 0.616, 0.608, 0.607])"
      ]
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(rf_clf, features, target, cv=5)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.61 accuracy with a standard deviation of 0.01\n"
     ]
    }
   ],
   "source": [
    "print(\"%0.2f accuracy with a standard deviation of %0.2f\" % (scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}